{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train and Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[19. 5G mobile networks DO NOT spread COVID-19...</td>\n",
       "      <td>nonrumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@Telegraph we will be very satisfied if #Nawa...</td>\n",
       "      <td>rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Coronavirus disease (COVID-19) advice for the...</td>\n",
       "      <td>nonrumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[@WSJ when Canadians of all people start shoot...</td>\n",
       "      <td>nonrumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[if the primary focus of a government isn't to...</td>\n",
       "      <td>nonrumour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              thread      label\n",
       "0  [19. 5G mobile networks DO NOT spread COVID-19...  nonrumour\n",
       "1  [@Telegraph we will be very satisfied if #Nawa...     rumour\n",
       "2  [Coronavirus disease (COVID-19) advice for the...  nonrumour\n",
       "3  [@WSJ when Canadians of all people start shoot...  nonrumour\n",
       "4  [if the primary focus of a government isn't to...  nonrumour"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "def load_data(dataName):\n",
    "    ids = []\n",
    "    with open('project-data/' + dataName + '.data.txt') as f:\n",
    "        for line in f.readlines():\n",
    "            ids.append(line.rstrip('\\n').split(','))\n",
    "\n",
    "    data = []\n",
    "    for seq in ids:\n",
    "        texts = []\n",
    "        try:\n",
    "            # proceed only if the source tweet exists\n",
    "            with open('project-data/crawled_tweets/' + dataName + '/' + seq[0] + '.json') as json_file:\n",
    "                source = json.load(json_file)['text']\n",
    "            texts.append(source)\n",
    "            for id in seq[1:]:\n",
    "                try: \n",
    "                    with open('project-data/crawled_tweets/' + dataName + '/' + id + '.json') as json_file:\n",
    "                        text = json.load(json_file)['text']\n",
    "                    texts.append(text)\n",
    "                except:\n",
    "                    continue\n",
    "            data.append(texts)\n",
    "        except:\n",
    "            data.append(texts)\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "# load data and labels\n",
    "trainData = load_data('train')\n",
    "devData = load_data('dev')\n",
    "trainLabel = [label.rstrip('\\n') for label in open(\"project-data/train.label.txt\", \"r\").readlines()]\n",
    "devLabel = [label.rstrip('\\n') for label in open(\"project-data/dev.label.txt\", \"r\").readlines()]\n",
    "assert(len(trainData) == len(trainLabel))\n",
    "assert(len(devData) == len(devLabel))\n",
    "\n",
    "# build dataframes\n",
    "train = pd.DataFrame({\"thread\" : trainData, \"label\": trainLabel})\n",
    "dev = pd.DataFrame({\"thread\" : devData, \"label\": devLabel})\n",
    "\n",
    "# remove empty thread\n",
    "train = train[train['thread'].map(lambda d: len(d)) > 0]\n",
    "dev = dev[dev['thread'].map(lambda d: len(d)) > 0]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labels = ['nonrumour', 'rumour']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train.label.to_list())\n",
    "y_train = encoder.transform(train.label.to_list())\n",
    "y_dev = encoder.transform(dev.label.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Counter({'nonrumour': 1390, 'rumour': 400})\n",
      "dev: Counter({'nonrumour': 456, 'rumour': 136})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('train: {}'.format(Counter(train.label)))\n",
    "print('dev: {}'.format(Counter(dev.label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2249789739276703"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(1388+455)/(400+135+1388+455)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[How Does COVID-19 Spread? https://t.co/TXHDeU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@brain_warrior I hate to keep saying it, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q. How are COVID-19 and influenza viruses dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Una de les Q&amp;amp;A on coronaviruses de la pàg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[@_truthpolitics We should absolutely blame th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              thread\n",
       "0  [How Does COVID-19 Spread? https://t.co/TXHDeU...\n",
       "1  [@brain_warrior I hate to keep saying it, but ...\n",
       "2  [Q. How are COVID-19 and influenza viruses dif...\n",
       "3  [Una de les Q&amp;A on coronaviruses de la pàg...\n",
       "4  [@_truthpolitics We should absolutely blame th..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = []\n",
    "with open('project-data/test.data.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        ids.append(line.rstrip('\\n').split(','))\n",
    "\n",
    "testData = []\n",
    "for seq in ids:\n",
    "    texts = []\n",
    "    try:\n",
    "        # proceed only if the source tweet exists\n",
    "        with open('project-data/tweet-objects/' + seq[0] + '.json') as json_file:\n",
    "            source = json.load(json_file)['text']\n",
    "        texts.append(source)\n",
    "        for id in seq[1:]:\n",
    "            try: \n",
    "                with open('project-data/tweet-objects/' + id + '.json') as json_file:\n",
    "                    text = json.load(json_file)['text']\n",
    "                texts.append(text)\n",
    "            except:\n",
    "                continue\n",
    "        testData.append(texts)\n",
    "    except:\n",
    "        testData.append(texts)\n",
    "        continue\n",
    "test = pd.DataFrame({\"thread\" : testData})\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing includes:\n",
    "1. remove twitter handles and urls\n",
    "2. lower case\n",
    "3. tokenize each tweet text into word tokens\n",
    "4. remove any word that does not contain any English alphabets in a list of words\n",
    "5. remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tree branch'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "remove_stopwords('tree and branch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1074: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1306: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1442: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:318: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:575: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=1,\n"
     ]
    }
   ],
   "source": [
    "# adapted from Assignment 1 code\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from string import punctuation\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.EMOJI)\n",
    "\n",
    "stopwords = set(stopwords.words('english')) #note: stopwords are all in lowercase\n",
    "\n",
    "def removeNonEnglish(tokens):\n",
    "    # remove any word that does not contain any English alphabets in a list of words\n",
    "    removed = []\n",
    "    for token in tokens:\n",
    "        alphabet = False\n",
    "        for char in token:\n",
    "            if char.isalpha():\n",
    "                alphabet = True\n",
    "                break\n",
    "        if alphabet:\n",
    "            removed.append(token)\n",
    "    return removed\n",
    "\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "words = set(nltk.corpus.words.words()) # a list of words provided by NLTK\n",
    "words = set([ word.lower() for word in words ]) #lowercase all the words for better matching\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "\n",
    "def preprocess(thread):\n",
    "    ts = []\n",
    "    for tweet in thread:\n",
    "        t = p.clean(tweet)\n",
    "        t = t.lower() # lowercase all words\n",
    "        t = t.split(' ') # tokenize each tweet into individual word tokens\n",
    "        t = removeNonEnglish(t) # remove any word that does not contain any English alphabets\n",
    "        # t = [token for token in t if not token in stopwords] # remove stopwords\n",
    "        t = [lemmatize(w) for w in t]\n",
    "        t = [w.strip(punctuation) for w in t] # remove punctuation\n",
    "        ts.append(' '.join(t))\n",
    "    return ts\n",
    "\n",
    "train[\"preprocessed\"] = [preprocess(thread) for thread in train['thread']]\n",
    "dev[\"preprocessed\"] = [preprocess(thread) for thread in dev['thread']]\n",
    "test[\"preprocessed\"] = [preprocess(thread) for thread in test['thread']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[19. 5G mobile networks DO NOT spread COVID-19...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[5g mobile network do not spread covid-19, 5g ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@Telegraph we will be very satisfied if #Nawa...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>[we will be very satisfy if nawazsharif resign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Coronavirus disease (COVID-19) advice for the...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[coronavirus disease covid-19 advice for the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[@WSJ when Canadians of all people start shoot...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[when canadian of all people start shooting we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[if the primary focus of a government isn't to...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[if the primary focus of a government isn't to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              thread      label  \\\n",
       "0  [19. 5G mobile networks DO NOT spread COVID-19...  nonrumour   \n",
       "1  [@Telegraph we will be very satisfied if #Nawa...     rumour   \n",
       "2  [Coronavirus disease (COVID-19) advice for the...  nonrumour   \n",
       "3  [@WSJ when Canadians of all people start shoot...  nonrumour   \n",
       "4  [if the primary focus of a government isn't to...  nonrumour   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  [5g mobile network do not spread covid-19, 5g ...  \n",
       "1  [we will be very satisfy if nawazsharif resign...  \n",
       "2  [coronavirus disease covid-19 advice for the p...  \n",
       "3  [when canadian of all people start shooting we...  \n",
       "4  [if the primary focus of a government isn't to...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max number of words in one tweet: 30\n"
     ]
    }
   ],
   "source": [
    "max_num_words = max(\n",
    "    max([len(tweet.split()) for thread in dev[\"preprocessed\"] for tweet in thread]),\n",
    "    max([len(tweet.split()) for thread in test[\"preprocessed\"] for tweet in thread]),\n",
    "    max([len(tweet.split()) for thread in train[\"preprocessed\"] for tweet in thread]))\n",
    "print('max number of words in one tweet: {}'.format(max_num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max number of tweets in one thread: 305\n"
     ]
    }
   ],
   "source": [
    "max_num_tweets = max(max([len(thread) for thread in dev[\"preprocessed\"]]),\n",
    "    max([len(thread) for thread in train[\"preprocessed\"]]),\n",
    "    max([len(thread) for thread in test[\"preprocessed\"]]))\n",
    "print('max number of tweets in one thread: {}'.format(max_num_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15851"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<UNK>\", split = ' ')\n",
    "tokenizer.fit_on_texts([tweet for thread in train['preprocessed'] for tweet in thread])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>xseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[19. 5G mobile networks DO NOT spread COVID-19...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[5g mobile network do not spread covid-19, 5g ...</td>\n",
       "      <td>[[29, 406, 644, 1888, 15, 17, 85, 27, 29, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@Telegraph we will be very satisfied if #Nawa...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>[we will be very satisfy if nawazsharif resign...</td>\n",
       "      <td>[[1, 34, 48, 2, 152, 1, 37, 5342, 5343, 161, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Coronavirus disease (COVID-19) advice for the...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[coronavirus disease covid-19 advice for the p...</td>\n",
       "      <td>[[20, 90, 27, 29, 820, 16, 3, 344, 1, 69, 9, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[@WSJ when Canadians of all people start shoot...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[when canadian of all people start shooting we...</td>\n",
       "      <td>[[1, 77, 7363, 7, 41, 25, 357, 1498, 125, 2128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[if the primary focus of a government isn't to...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[if the primary focus of a government isn't to...</td>\n",
       "      <td>[[37, 3, 5355, 2236, 7, 4, 328, 366, 5, 3318, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              thread      label  \\\n",
       "0  [19. 5G mobile networks DO NOT spread COVID-19...  nonrumour   \n",
       "1  [@Telegraph we will be very satisfied if #Nawa...     rumour   \n",
       "2  [Coronavirus disease (COVID-19) advice for the...  nonrumour   \n",
       "3  [@WSJ when Canadians of all people start shoot...  nonrumour   \n",
       "4  [if the primary focus of a government isn't to...  nonrumour   \n",
       "\n",
       "                                        preprocessed  \\\n",
       "0  [5g mobile network do not spread covid-19, 5g ...   \n",
       "1  [we will be very satisfy if nawazsharif resign...   \n",
       "2  [coronavirus disease covid-19 advice for the p...   \n",
       "3  [when canadian of all people start shooting we...   \n",
       "4  [if the primary focus of a government isn't to...   \n",
       "\n",
       "                                                xseq  \n",
       "0  [[29, 406, 644, 1888, 15, 17, 85, 27, 29, 1, 1...  \n",
       "1  [[1, 34, 48, 2, 152, 1, 37, 5342, 5343, 161, 3...  \n",
       "2  [[20, 90, 27, 29, 820, 16, 3, 344, 1, 69, 9, 1...  \n",
       "3  [[1, 77, 7363, 7, 41, 25, 357, 1498, 125, 2128...  \n",
       "4  [[37, 3, 5355, 2236, 7, 4, 328, 366, 5, 3318, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenise the input into word sequences\n",
    "train['xseq'] = [tokenizer.texts_to_sequences(thread) for thread in train.thread]\n",
    "dev['xseq'] = [tokenizer.texts_to_sequences(thread) for thread in dev.thread]\n",
    "test['xseq'] = [tokenizer.texts_to_sequences(thread) for thread in test.thread]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3], [4,5,6]])\n",
    "np.reshape(a, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 29, 406, 644, ...,   0,   0,   0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def padding(max_num_tweets, max_num_words, data):\n",
    "    padded = np.zeros((len(data), max_num_tweets, max_num_words))\n",
    "    for i in range(len(data)):\n",
    "        thread_seq = data[i]\n",
    "        thread_len = len(thread_seq)\n",
    "        padded[i] = np.concatenate((pad_sequences(thread_seq, padding='post', maxlen=max_num_words), np.zeros((max_num_tweets-thread_len, max_num_words))), axis=0)\n",
    "    result = np.zeros((len(data), max_num_tweets*max_num_words))\n",
    "    for i in range(len(data)):\n",
    "        thread = padded[i]\n",
    "        result[i] = np.reshape(thread, -1)\n",
    "    return result\n",
    "\n",
    "\n",
    "train_xseq_padded= padding(max_num_tweets, max_num_words, train.xseq.values).astype(int)\n",
    "dev_xseq_padded = padding(max_num_tweets, max_num_words, dev.xseq.values).astype(int)\n",
    "test_xseq_padded = padding(max_num_tweets, max_num_words, test.xseq.values).astype(int)\n",
    "train_xseq_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "model_w2v = api.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# creating an matrix with zeroes of shape vocab x embedding dimension\n",
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "# Iterate through word, index in the dictionary\n",
    "for word, i in word_index.items():\n",
    "    # extract the corresponding vector for the vocab indice of same word\n",
    "    try:\n",
    "        embedding_vector = model_w2v[word]\n",
    "        if embedding_vector is not None:\n",
    "            # Storing it in a matrix\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13116"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([line.any() for line in embedding_matrix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model and Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, TimeDistributed, Embedding, Dense, Dropout, Masking\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Size and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train), y_train)\n",
    "emb_dim = 50\n",
    "def train_model(lstm_units, lr, epochs, batch_size):\n",
    "    model = Sequential(name=\"lstm\")\n",
    "    embedding_layer = Embedding(input_dim=vocab_size, output_dim=emb_dim,\n",
    "                                input_length=max_num_words*max_num_tweets, weights=[embedding_matrix], trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Masking(mask_value=0))\n",
    "    model.add(LSTM(lstm_units))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer = Adam(lr=lr),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['accuracy', keras.metrics.FalseNegatives(name=\"fn\"), keras.metrics.FalsePositives(name=\"fp\"),\n",
    "                            keras.metrics.TrueNegatives(name=\"tn\"), keras.metrics.TruePositives(name=\"tp\")])\n",
    "    model.fit(\n",
    "    train_xseq_padded,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(dev_xseq_padded, y_dev),\n",
    "    class_weight=class_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ### Testing: batch_size = 128, epochs = 5, lr = 0.01, lstm_units = 128\n",
      "Train on 1790 samples, validate on 592 samples\n",
      "Epoch 1/5\n",
      "1790/1790 [==============================] - 673s 376ms/step - loss: 0.5295 - accuracy: 0.7670 - fn: 391.0000 - fp: 26.0000 - tn: 1364.0000 - tp: 9.0000 - val_loss: 0.5251 - val_accuracy: 0.7703 - val_fn: 136.0000 - val_fp: 0.0000e+00 - val_tn: 456.0000 - val_tp: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1790/1790 [==============================] - 659s 368ms/step - loss: 0.4800 - accuracy: 0.7737 - fn: 374.0000 - fp: 31.0000 - tn: 1359.0000 - tp: 26.0000 - val_loss: 0.4831 - val_accuracy: 0.7652 - val_fn: 124.0000 - val_fp: 15.0000 - val_tn: 441.0000 - val_tp: 12.0000\n",
      "Epoch 3/5\n",
      "1790/1790 [==============================] - 653s 365ms/step - loss: 0.4347 - accuracy: 0.7888 - fn: 285.0000 - fp: 93.0000 - tn: 1297.0000 - tp: 115.0000 - val_loss: 0.4920 - val_accuracy: 0.7720 - val_fn: 134.0000 - val_fp: 1.0000 - val_tn: 455.0000 - val_tp: 2.0000\n",
      "Epoch 4/5\n",
      "1790/1790 [==============================] - 607s 339ms/step - loss: 0.4291 - accuracy: 0.7911 - fn: 334.0000 - fp: 40.0000 - tn: 1350.0000 - tp: 66.0000 - val_loss: 0.4374 - val_accuracy: 0.7855 - val_fn: 87.0000 - val_fp: 40.0000 - val_tn: 416.0000 - val_tp: 49.0000\n",
      "Epoch 5/5\n",
      "1790/1790 [==============================] - 596s 333ms/step - loss: 0.3830 - accuracy: 0.8207 - fn: 201.0000 - fp: 120.0000 - tn: 1270.0000 - tp: 199.0000 - val_loss: 0.4091 - val_accuracy: 0.7922 - val_fn: 82.0000 - val_fp: 41.0000 - val_tn: 415.0000 - val_tp: 54.0000\n",
      "--- ### Testing: batch_size = 64, epochs = 5, lr = 0.01, lstm_units = 128\n",
      "Train on 1790 samples, validate on 592 samples\n",
      "Epoch 1/5\n",
      "1790/1790 [==============================] - 288s 161ms/step - loss: 0.5315 - accuracy: 0.7676 - fn: 391.0000 - fp: 25.0000 - tn: 1365.0000 - tp: 9.0000 - val_loss: 0.4992 - val_accuracy: 0.7618 - val_fn: 133.0000 - val_fp: 8.0000 - val_tn: 448.0000 - val_tp: 3.0000\n",
      "Epoch 2/5\n",
      "1790/1790 [==============================] - 287s 160ms/step - loss: 0.4614 - accuracy: 0.7732 - fn: 347.0000 - fp: 59.0000 - tn: 1331.0000 - tp: 53.0000 - val_loss: 0.4592 - val_accuracy: 0.7669 - val_fn: 135.0000 - val_fp: 3.0000 - val_tn: 453.0000 - val_tp: 1.0000\n",
      "Epoch 3/5\n",
      "1790/1790 [==============================] - 306s 171ms/step - loss: 0.4230 - accuracy: 0.7994 - fn: 288.0000 - fp: 71.0000 - tn: 1319.0000 - tp: 112.0000 - val_loss: 0.4794 - val_accuracy: 0.7635 - val_fn: 104.0000 - val_fp: 36.0000 - val_tn: 420.0000 - val_tp: 32.0000\n",
      "Epoch 4/5\n",
      "1790/1790 [==============================] - 292s 163ms/step - loss: 0.4095 - accuracy: 0.8095 - fn: 256.0000 - fp: 85.0000 - tn: 1305.0000 - tp: 144.0000 - val_loss: 0.4227 - val_accuracy: 0.8024 - val_fn: 64.0000 - val_fp: 53.0000 - val_tn: 403.0000 - val_tp: 72.0000\n",
      "Epoch 5/5\n",
      "1790/1790 [==============================] - 292s 163ms/step - loss: 0.3672 - accuracy: 0.8374 - fn: 168.0000 - fp: 123.0000 - tn: 1267.0000 - tp: 232.0000 - val_loss: 0.4131 - val_accuracy: 0.8074 - val_fn: 67.0000 - val_fp: 47.0000 - val_tn: 409.0000 - val_tp: 69.0000\n",
      "--- ### Testing: batch_size = 32, epochs = 5, lr = 0.01, lstm_units = 128\n",
      "Train on 1790 samples, validate on 592 samples\n",
      "Epoch 1/5\n",
      "1790/1790 [==============================] - 415s 232ms/step - loss: 0.5130 - accuracy: 0.7737 - fn: 386.0000 - fp: 19.0000 - tn: 1371.0000 - tp: 14.0000 - val_loss: 0.4713 - val_accuracy: 0.7601 - val_fn: 128.0000 - val_fp: 14.0000 - val_tn: 442.0000 - val_tp: 8.0000\n",
      "Epoch 2/5\n",
      "1790/1790 [==============================] - 412s 230ms/step - loss: 0.4294 - accuracy: 0.7911 - fn: 295.0000 - fp: 79.0000 - tn: 1311.0000 - tp: 105.0000 - val_loss: 0.4265 - val_accuracy: 0.8024 - val_fn: 71.0000 - val_fp: 46.0000 - val_tn: 410.0000 - val_tp: 65.0000\n",
      "Epoch 3/5\n",
      "1790/1790 [==============================] - 413s 231ms/step - loss: 0.3964 - accuracy: 0.8179 - fn: 197.0000 - fp: 129.0000 - tn: 1261.0000 - tp: 203.0000 - val_loss: 0.4204 - val_accuracy: 0.7753 - val_fn: 106.0000 - val_fp: 27.0000 - val_tn: 429.0000 - val_tp: 30.0000\n",
      "Epoch 4/5\n",
      "1790/1790 [==============================] - 414s 231ms/step - loss: 0.3511 - accuracy: 0.8369 - fn: 190.0000 - fp: 102.0000 - tn: 1288.0000 - tp: 210.0000 - val_loss: 0.3850 - val_accuracy: 0.8108 - val_fn: 79.0000 - val_fp: 33.0000 - val_tn: 423.0000 - val_tp: 57.0000\n",
      "Epoch 5/5\n",
      "1790/1790 [==============================] - 412s 230ms/step - loss: 0.3264 - accuracy: 0.8648 - fn: 148.0000 - fp: 94.0000 - tn: 1296.0000 - tp: 252.0000 - val_loss: 0.4014 - val_accuracy: 0.8074 - val_fn: 49.0000 - val_fp: 65.0000 - val_tn: 391.0000 - val_tp: 87.0000\n",
      "--- ### Testing: batch_size = 16, epochs = 5, lr = 0.01, lstm_units = 128\n",
      "Train on 1790 samples, validate on 592 samples\n",
      "Epoch 1/5\n",
      "1790/1790 [==============================] - 560s 313ms/step - loss: 0.5107 - accuracy: 0.7698 - fn: 384.0000 - fp: 28.0000 - tn: 1362.0000 - tp: 16.0000 - val_loss: 0.4840 - val_accuracy: 0.7720 - val_fn: 133.0000 - val_fp: 2.0000 - val_tn: 454.0000 - val_tp: 3.0000\n",
      "Epoch 2/5\n",
      "1790/1790 [==============================] - 568s 317ms/step - loss: 0.4849 - accuracy: 0.7709 - fn: 363.0000 - fp: 47.0000 - tn: 1343.0000 - tp: 37.0000 - val_loss: 0.5070 - val_accuracy: 0.7703 - val_fn: 136.0000 - val_fp: 0.0000e+00 - val_tn: 456.0000 - val_tp: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1790/1790 [==============================] - 568s 317ms/step - loss: 0.4527 - accuracy: 0.7827 - fn: 333.0000 - fp: 56.0000 - tn: 1334.0000 - tp: 67.0000 - val_loss: 0.4420 - val_accuracy: 0.7821 - val_fn: 96.0000 - val_fp: 33.0000 - val_tn: 423.0000 - val_tp: 40.0000\n",
      "Epoch 4/5\n",
      "1790/1790 [==============================] - 571s 319ms/step - loss: 0.4200 - accuracy: 0.7966 - fn: 256.0000 - fp: 108.0000 - tn: 1282.0000 - tp: 144.0000 - val_loss: 0.4295 - val_accuracy: 0.7872 - val_fn: 95.0000 - val_fp: 31.0000 - val_tn: 425.0000 - val_tp: 41.0000\n",
      "Epoch 5/5\n",
      "1790/1790 [==============================] - 571s 319ms/step - loss: 0.3741 - accuracy: 0.8218 - fn: 219.0000 - fp: 100.0000 - tn: 1290.0000 - tp: 181.0000 - val_loss: 0.3922 - val_accuracy: 0.8159 - val_fn: 68.0000 - val_fp: 41.0000 - val_tn: 415.0000 - val_tp: 68.0000\n",
      "--- ### Testing: batch_size = 8, epochs = 5, lr = 0.01, lstm_units = 128\n",
      "Train on 1790 samples, validate on 592 samples\n",
      "Epoch 1/5\n",
      "1790/1790 [==============================] - 1119s 625ms/step - loss: 0.5126 - accuracy: 0.7754 - fn: 386.0000 - fp: 16.0000 - tn: 1374.0000 - tp: 14.0000 - val_loss: 0.5071 - val_accuracy: 0.7703 - val_fn: 136.0000 - val_fp: 0.0000e+00 - val_tn: 456.0000 - val_tp: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1790/1790 [==============================] - 1099s 614ms/step - loss: 0.4551 - accuracy: 0.7866 - fn: 325.0000 - fp: 57.0000 - tn: 1333.0000 - tp: 75.0000 - val_loss: 0.4632 - val_accuracy: 0.7736 - val_fn: 88.0000 - val_fp: 46.0000 - val_tn: 410.0000 - val_tp: 48.0000\n",
      "Epoch 3/5\n",
      "1790/1790 [==============================] - 1063s 594ms/step - loss: 0.4110 - accuracy: 0.8084 - fn: 236.0000 - fp: 107.0000 - tn: 1283.0000 - tp: 164.0000 - val_loss: 0.5254 - val_accuracy: 0.7889 - val_fn: 121.0000 - val_fp: 4.0000 - val_tn: 452.0000 - val_tp: 15.0000\n",
      "Epoch 4/5\n",
      "1790/1790 [==============================] - 1067s 596ms/step - loss: 0.3955 - accuracy: 0.8335 - fn: 207.0000 - fp: 91.0000 - tn: 1299.0000 - tp: 193.0000 - val_loss: 0.4174 - val_accuracy: 0.8074 - val_fn: 63.0000 - val_fp: 51.0000 - val_tn: 405.0000 - val_tp: 73.0000\n",
      "Epoch 5/5\n",
      "1136/1790 [==================>...........] - ETA: 10:19 - loss: 0.3793 - accuracy: 0.8451 - fn: 104.0000 - fp: 72.0000 - tn: 803.0000 - tp: 157.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7ee7be751c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_sizeL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--- ### Testing: batch_size = {}, epochs = {}, lr = {}, lstm_units = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-6b40dae9dda1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(lstm_units, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_xseq_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     class_weight=class_weights)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochsL = [5, 10, 15, 20]\n",
    "batch_sizeL = [128, 64, 32, 16, 8]\n",
    "lstm_units = 128\n",
    "lr=0.01\n",
    "\n",
    "models = []\n",
    "for epochs in epochsL:\n",
    "    for batch_size in batch_sizeL:\n",
    "        print('--- ### Testing: batch_size = {}, epochs = {}, lr = {}, lstm_units = {}'.format(batch_size, epochs, lr, lstm_units))\n",
    "        models.append(train_model(lstm_units, lr, epochs, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Batch size: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64409222, 2.235     ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsL = [5, 10, 15, 20]\n",
    "batch_sizeL = [128, 64, 32, 16, 8]\n",
    "lstm_units = 128\n",
    "lr=0.01\n",
    "\n",
    "models = []\n",
    "for epochs in epochsL:\n",
    "    for batch_size in batch_sizeL:\n",
    "        print('--- ### Testing: batch_size = {}, epochs = {}, lr = {}, lstm_units = {}'.format(batch_size, epochs, lr, lstm_units))\n",
    "        models.append(train_model(lstm_units, lr, epochs, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1788 samples, validate on 590 samples\n",
      "Epoch 1/10\n",
      "1788/1788 [==============================] - 1763s 986ms/step - loss: 0.5140 - accuracy: 0.7573 - fn: 365.0000 - fp: 69.0000 - tn: 1319.0000 - tp: 35.0000 - val_loss: 0.4907 - val_accuracy: 0.7695 - val_fn: 135.0000 - val_fp: 1.0000 - val_tn: 454.0000 - val_tp: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1788/1788 [==============================] - 741s 415ms/step - loss: 0.3838 - accuracy: 0.8322 - fn: 211.0000 - fp: 89.0000 - tn: 1299.0000 - tp: 189.0000 - val_loss: 0.4543 - val_accuracy: 0.7458 - val_fn: 29.0000 - val_fp: 121.0000 - val_tn: 334.0000 - val_tp: 106.0000\n",
      "Epoch 3/10\n",
      "1788/1788 [==============================] - 408s 228ms/step - loss: 0.2574 - accuracy: 0.9139 - fn: 94.0000 - fp: 60.0000 - tn: 1328.0000 - tp: 306.0000 - val_loss: 0.3384 - val_accuracy: 0.8559 - val_fn: 44.0000 - val_fp: 41.0000 - val_tn: 414.0000 - val_tp: 91.0000\n",
      "Epoch 4/10\n",
      "1788/1788 [==============================] - 450s 252ms/step - loss: 0.0968 - accuracy: 0.9698 - fn: 30.0000 - fp: 24.0000 - tn: 1364.0000 - tp: 370.0000 - val_loss: 0.4532 - val_accuracy: 0.8542 - val_fn: 71.0000 - val_fp: 15.0000 - val_tn: 440.0000 - val_tp: 64.0000\n",
      "Epoch 5/10\n",
      "1788/1788 [==============================] - 417s 233ms/step - loss: 0.0431 - accuracy: 0.9894 - fn: 15.0000 - fp: 4.0000 - tn: 1384.0000 - tp: 385.0000 - val_loss: 0.4186 - val_accuracy: 0.8814 - val_fn: 33.0000 - val_fp: 37.0000 - val_tn: 418.0000 - val_tp: 102.0000\n",
      "Epoch 6/10\n",
      "1788/1788 [==============================] - 466s 261ms/step - loss: 0.0131 - accuracy: 0.9978 - fn: 3.0000 - fp: 1.0000 - tn: 1387.0000 - tp: 397.0000 - val_loss: 0.5567 - val_accuracy: 0.8915 - val_fn: 28.0000 - val_fp: 36.0000 - val_tn: 419.0000 - val_tp: 107.0000\n",
      "Epoch 7/10\n",
      "1788/1788 [==============================] - 519s 290ms/step - loss: 0.0158 - accuracy: 0.9955 - fn: 6.0000 - fp: 2.0000 - tn: 1386.0000 - tp: 394.0000 - val_loss: 0.4345 - val_accuracy: 0.8831 - val_fn: 31.0000 - val_fp: 38.0000 - val_tn: 417.0000 - val_tp: 104.0000\n",
      "Epoch 8/10\n",
      "1788/1788 [==============================] - 407s 227ms/step - loss: 0.0112 - accuracy: 0.9972 - fn: 3.0000 - fp: 2.0000 - tn: 1386.0000 - tp: 397.0000 - val_loss: 0.4384 - val_accuracy: 0.8780 - val_fn: 39.0000 - val_fp: 33.0000 - val_tn: 422.0000 - val_tp: 96.0000\n",
      "Epoch 9/10\n",
      "1788/1788 [==============================] - 438s 245ms/step - loss: 0.0057 - accuracy: 0.9983 - fn: 3.0000 - fp: 0.0000e+00 - tn: 1388.0000 - tp: 397.0000 - val_loss: 0.5690 - val_accuracy: 0.8949 - val_fn: 20.0000 - val_fp: 42.0000 - val_tn: 413.0000 - val_tp: 115.0000\n",
      "Epoch 10/10\n",
      "1788/1788 [==============================] - 502s 281ms/step - loss: 0.0056 - accuracy: 0.9983 - fn: 2.0000 - fp: 1.0000 - tn: 1387.0000 - tp: 398.0000 - val_loss: 0.5384 - val_accuracy: 0.8949 - val_fn: 27.0000 - val_fp: 35.0000 - val_tn: 420.0000 - val_tp: 108.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ce7fecbb5263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_xseq_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing Accuracy:  {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_xseq_padded,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(dev_xseq_padded, y_dev),\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_xseq_padded, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 421, 1: 137})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_label(score):\n",
    "    if score > 0.5:\n",
    "        return 1\n",
    "    return 0\n",
    "pred_label = [predict_label(s) for s in pred]\n",
    "Counter(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Id': list(range(len(test_xseq_padded))),'Predicted': pred_label}).to_csv('test.pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('test.pred.csv', 'wb') as mf:\n",
    "    wr = csv.writer(mf, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1788 samples, validate on 590 samples\n",
      "Epoch 1/10\n",
      "1788/1788 [==============================] - 1602s 896ms/step - loss: 0.5358 - accuracy: 0.7494 - fn: 365.0000 - fp: 83.0000 - tn: 1305.0000 - tp: 35.0000 - val_loss: 0.4891 - val_accuracy: 0.7712 - val_fn: 132.0000 - val_fp: 3.0000 - val_tn: 452.0000 - val_tp: 3.0000\n",
      "Epoch 2/10\n",
      "1788/1788 [==============================] - 1564s 875ms/step - loss: 0.4721 - accuracy: 0.7740 - fn: 367.0000 - fp: 37.0000 - tn: 1351.0000 - tp: 33.0000 - val_loss: 0.4849 - val_accuracy: 0.7627 - val_fn: 129.0000 - val_fp: 11.0000 - val_tn: 444.0000 - val_tp: 6.0000\n",
      "Epoch 3/10\n",
      " 640/1788 [=========>....................] - ETA: 16:12 - loss: 0.4426 - accuracy: 0.7953 - fn: 98.0000 - fp: 33.0000 - tn: 452.0000 - tp: 57.0000"
     ]
    }
   ],
   "source": [
    "lstm_units = 256\n",
    "trainable = False\n",
    "lr = 0.008\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# epochs, learning rate, batch_size, early_stopping\n",
    "\n",
    "emb_dim = 50 # fixed\n",
    "\n",
    "model = Sequential(name=\"lstm\")\n",
    "model.add(Embedding(input_dim = vocab_size, output_dim = emb_dim,\n",
    "                    input_length = max_num_words * max_num_tweets, weights=[embedding_matrix], trainable=trainable))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Masking(mask_value=0))\n",
    "model.add(LSTM(lstm_units))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = Adam(lr=lr),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['accuracy', keras.metrics.FalseNegatives(name=\"fn\"), keras.metrics.FalsePositives(name=\"fp\"),\n",
    "                        keras.metrics.TrueNegatives(name=\"tn\"), keras.metrics.TruePositives(name=\"tp\"),])\n",
    "\n",
    "model.fit(\n",
    "    train_xseq_padded,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(dev_xseq_padded, y_dev),\n",
    "    class_weight=class_weights\n",
    ")\n",
    "pred = model.predict(test_xseq_padded, batch_size=64)\n",
    "pred_label = [predict_label(s) for s in pred]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
