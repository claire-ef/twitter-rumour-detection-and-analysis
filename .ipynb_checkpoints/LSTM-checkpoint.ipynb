{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train and Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[19. 5G mobile networks DO NOT spread COVID-19...</td>\n",
       "      <td>nonrumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@Telegraph we will be very satisfied if #Nawa...</td>\n",
       "      <td>rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Coronavirus disease (COVID-19) advice for the...</td>\n",
       "      <td>nonrumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[@WSJ when Canadians of all people start shoot...</td>\n",
       "      <td>nonrumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[if the primary focus of a government isn't to...</td>\n",
       "      <td>nonrumour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              thread      label\n",
       "0  [19. 5G mobile networks DO NOT spread COVID-19...  nonrumour\n",
       "1  [@Telegraph we will be very satisfied if #Nawa...     rumour\n",
       "2  [Coronavirus disease (COVID-19) advice for the...  nonrumour\n",
       "3  [@WSJ when Canadians of all people start shoot...  nonrumour\n",
       "4  [if the primary focus of a government isn't to...  nonrumour"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "def load_data(dataName):\n",
    "    ids = []\n",
    "    with open('project-data/' + dataName + '.data.txt') as f:\n",
    "        for line in f.readlines():\n",
    "            ids.append(line.rstrip('\\n').split(','))\n",
    "\n",
    "    data = []\n",
    "    for seq in ids:\n",
    "        texts = []\n",
    "        try:\n",
    "            # proceed only if the source tweet exists\n",
    "            with open('project-data/crawled_tweets/' + dataName + '/' + seq[0] + '.json') as json_file:\n",
    "                source = json.load(json_file)['text']\n",
    "            texts.append(source)\n",
    "            for id in seq[1:]:\n",
    "                try: \n",
    "                    with open('project-data/crawled_tweets/' + dataName + '/' + id + '.json') as json_file:\n",
    "                        text = json.load(json_file)['text']\n",
    "                    texts.append(text)\n",
    "                except:\n",
    "                    continue\n",
    "            data.append(texts)\n",
    "        except:\n",
    "            data.append(texts)\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "# load data and labels\n",
    "trainData = load_data('train')\n",
    "devData = load_data('dev')\n",
    "trainLabel = [label.rstrip('\\n') for label in open(\"project-data/train.label.txt\", \"r\").readlines()]\n",
    "devLabel = [label.rstrip('\\n') for label in open(\"project-data/dev.label.txt\", \"r\").readlines()]\n",
    "assert(len(trainData) == len(trainLabel))\n",
    "assert(len(devData) == len(devLabel))\n",
    "\n",
    "# build dataframes\n",
    "train = pd.DataFrame({\"thread\" : trainData, \"label\": trainLabel})\n",
    "dev = pd.DataFrame({\"thread\" : devData, \"label\": devLabel})\n",
    "\n",
    "# remove empty thread\n",
    "train = train[train['thread'].map(lambda d: len(d)) > 0]\n",
    "dev = dev[dev['thread'].map(lambda d: len(d)) > 0]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labels = ['nonrumour', 'rumour']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train.label.to_list())\n",
    "y_train = encoder.transform(train.label.to_list())\n",
    "y_dev = encoder.transform(dev.label.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Counter({'nonrumour': 1390, 'rumour': 400})\n",
      "dev: Counter({'nonrumour': 456, 'rumour': 136})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('train: {}'.format(Counter(train.label)))\n",
    "print('dev: {}'.format(Counter(dev.label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[How Does COVID-19 Spread? https://t.co/TXHDeU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@brain_warrior I hate to keep saying it, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q. How are COVID-19 and influenza viruses dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Una de les Q&amp;amp;A on coronaviruses de la pàg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[@_truthpolitics We should absolutely blame th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              thread\n",
       "0  [How Does COVID-19 Spread? https://t.co/TXHDeU...\n",
       "1  [@brain_warrior I hate to keep saying it, but ...\n",
       "2  [Q. How are COVID-19 and influenza viruses dif...\n",
       "3  [Una de les Q&amp;A on coronaviruses de la pàg...\n",
       "4  [@_truthpolitics We should absolutely blame th..."
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = []\n",
    "with open('project-data/test.data.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        ids.append(line.rstrip('\\n').split(','))\n",
    "\n",
    "testData = []\n",
    "for seq in ids:\n",
    "    texts = []\n",
    "    try:\n",
    "        # proceed only if the source tweet exists\n",
    "        with open('project-data/tweet-objects/' + seq[0] + '.json') as json_file:\n",
    "            source = json.load(json_file)['text']\n",
    "        texts.append(source)\n",
    "        for id in seq[1:]:\n",
    "            try: \n",
    "                with open('project-data/tweet-objects/' + id + '.json') as json_file:\n",
    "                    text = json.load(json_file)['text']\n",
    "                texts.append(text)\n",
    "            except:\n",
    "                continue\n",
    "        testData.append(texts)\n",
    "    except:\n",
    "        testData.append(texts)\n",
    "        continue\n",
    "test = pd.DataFrame({\"thread\" : testData})\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing includes:\n",
    "1. remove twitter handles and urls\n",
    "2. lower case\n",
    "3. tokenize each tweet text into word tokens\n",
    "4. remove any word that does not contain any English alphabets in a list of words\n",
    "5. remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from Assignment 1 code\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from string import punctuation\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.EMOJI)\n",
    "\n",
    "stopwords = set(stopwords.words('english')) #note: stopwords are all in lowercase\n",
    "\n",
    "def removeNonEnglish(tokens):\n",
    "    # remove any word that does not contain any English alphabets in a list of words\n",
    "    removed = []\n",
    "    for token in tokens:\n",
    "        alphabet = False\n",
    "        for char in token:\n",
    "            if char.isalpha():\n",
    "                alphabet = True\n",
    "                break\n",
    "        if alphabet:\n",
    "            removed.append(token)\n",
    "    return removed\n",
    "\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "words = set(nltk.corpus.words.words()) #a list of words provided by NLTK\n",
    "words = set([ word.lower() for word in words ]) #lowercase all the words for better matching\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "\n",
    "def preprocess(thread):\n",
    "    ts = []\n",
    "    for tweet in thread:\n",
    "        t = p.clean(tweet)\n",
    "        t = t.lower() # lowercase all words\n",
    "        t = t.split(' ') # tokenize each tweet into individual word tokens\n",
    "        t = removeNonEnglish(t) # remove any word that does not contain any English alphabets\n",
    "        # t = [token for token in t if not token in stopwords] # remove stopwords\n",
    "        t = [lemmatize(w) for w in t]\n",
    "        t = [w.strip(punctuation) for w in t] # remove punctuation\n",
    "        ts.append(' '.join(t))\n",
    "    return ts\n",
    "\n",
    "train[\"preprocessed\"] = [preprocess(thread) for thread in train['thread']]\n",
    "dev[\"preprocessed\"] = [preprocess(thread) for thread in dev['thread']]\n",
    "test[\"preprocessed\"] = [preprocess(thread) for thread in test['thread']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[19. 5G mobile networks DO NOT spread COVID-19...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[5g mobile network do not spread covid-19, 5g ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@Telegraph we will be very satisfied if #Nawa...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>[we will be very satisfy if nawazsharif resign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Coronavirus disease (COVID-19) advice for the...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[coronavirus disease covid-19 advice for the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[@WSJ when Canadians of all people start shoot...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[when canadian of all people start shooting we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[if the primary focus of a government isn't to...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[if the primary focus of a government isn't to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              thread      label  \\\n",
       "0  [19. 5G mobile networks DO NOT spread COVID-19...  nonrumour   \n",
       "1  [@Telegraph we will be very satisfied if #Nawa...     rumour   \n",
       "2  [Coronavirus disease (COVID-19) advice for the...  nonrumour   \n",
       "3  [@WSJ when Canadians of all people start shoot...  nonrumour   \n",
       "4  [if the primary focus of a government isn't to...  nonrumour   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  [5g mobile network do not spread covid-19, 5g ...  \n",
       "1  [we will be very satisfy if nawazsharif resign...  \n",
       "2  [coronavirus disease covid-19 advice for the p...  \n",
       "3  [when canadian of all people start shooting we...  \n",
       "4  [if the primary focus of a government isn't to...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max number of words in one tweet: 30\n"
     ]
    }
   ],
   "source": [
    "max_num_words = max(\n",
    "    max([len(tweet.split()) for thread in dev[\"preprocessed\"] for tweet in thread]),\n",
    "    max([len(tweet.split()) for thread in test[\"preprocessed\"] for tweet in thread]),\n",
    "    max([len(tweet.split()) for thread in train[\"preprocessed\"] for tweet in thread]))\n",
    "print('max number of words in one tweet: {}'.format(max_num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max number of tweets in one thread: 305\n"
     ]
    }
   ],
   "source": [
    "max_num_tweets = max(max([len(thread) for thread in dev[\"preprocessed\"]]),\n",
    "    max([len(thread) for thread in train[\"preprocessed\"]]),\n",
    "    max([len(thread) for thread in test[\"preprocessed\"]]))\n",
    "print('max number of tweets in one thread: {}'.format(max_num_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15851"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<UNK>\", split = ' ')\n",
    "tokenizer.fit_on_texts([tweet for thread in train['preprocessed'] for tweet in thread])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>xseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[19. 5G mobile networks DO NOT spread COVID-19...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[5g mobile network do not spread covid-19, 5g ...</td>\n",
       "      <td>[[29, 406, 644, 1888, 15, 17, 85, 27, 29, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@Telegraph we will be very satisfied if #Nawa...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>[we will be very satisfy if nawazsharif resign...</td>\n",
       "      <td>[[1, 34, 48, 2, 152, 1, 37, 5342, 5343, 161, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Coronavirus disease (COVID-19) advice for the...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[coronavirus disease covid-19 advice for the p...</td>\n",
       "      <td>[[20, 90, 27, 29, 820, 16, 3, 344, 1, 69, 9, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[@WSJ when Canadians of all people start shoot...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[when canadian of all people start shooting we...</td>\n",
       "      <td>[[1, 77, 7363, 7, 41, 25, 357, 1498, 125, 2128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[if the primary focus of a government isn't to...</td>\n",
       "      <td>nonrumour</td>\n",
       "      <td>[if the primary focus of a government isn't to...</td>\n",
       "      <td>[[37, 3, 5355, 2236, 7, 4, 328, 366, 5, 3318, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              thread      label  \\\n",
       "0  [19. 5G mobile networks DO NOT spread COVID-19...  nonrumour   \n",
       "1  [@Telegraph we will be very satisfied if #Nawa...     rumour   \n",
       "2  [Coronavirus disease (COVID-19) advice for the...  nonrumour   \n",
       "3  [@WSJ when Canadians of all people start shoot...  nonrumour   \n",
       "4  [if the primary focus of a government isn't to...  nonrumour   \n",
       "\n",
       "                                        preprocessed  \\\n",
       "0  [5g mobile network do not spread covid-19, 5g ...   \n",
       "1  [we will be very satisfy if nawazsharif resign...   \n",
       "2  [coronavirus disease covid-19 advice for the p...   \n",
       "3  [when canadian of all people start shooting we...   \n",
       "4  [if the primary focus of a government isn't to...   \n",
       "\n",
       "                                                xseq  \n",
       "0  [[29, 406, 644, 1888, 15, 17, 85, 27, 29, 1, 1...  \n",
       "1  [[1, 34, 48, 2, 152, 1, 37, 5342, 5343, 161, 3...  \n",
       "2  [[20, 90, 27, 29, 820, 16, 3, 344, 1, 69, 9, 1...  \n",
       "3  [[1, 77, 7363, 7, 41, 25, 357, 1498, 125, 2128...  \n",
       "4  [[37, 3, 5355, 2236, 7, 4, 328, 366, 5, 3318, ...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenise the input into word sequences\n",
    "train['xseq'] = [tokenizer.texts_to_sequences(thread) for thread in train.thread]\n",
    "dev['xseq'] = [tokenizer.texts_to_sequences(thread) for thread in dev.thread]\n",
    "test['xseq'] = [tokenizer.texts_to_sequences(thread) for thread in test.thread]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   29,   406,   644, ...,     0,     0,     0],\n",
       "       [   29,   406,   644, ...,     0,     0,     0],\n",
       "       [13012,     3,    24, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     0,     0,     0],\n",
       "       [    0,     0,     0, ...,     0,     0,     0],\n",
       "       [    0,     0,     0, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def padding(max_num_tweets, max_num_words, data):\n",
    "    padded = np.zeros((len(data), max_num_tweets, max_num_words))\n",
    "    for i in range(len(data)):\n",
    "        thread_seq = data[i]\n",
    "        thread_len = len(thread_seq)\n",
    "        padded[i] = np.concatenate((pad_sequences(thread_seq, padding='post', maxlen=max_num_words), np.zeros((max_num_tweets-thread_len, max_num_words))), axis=0)\n",
    "    return padded\n",
    "#train['xseq_padded'] = [pad_sequences(thread, padding='post', maxlen=max_num_words) for thread in train.xseq]\n",
    "#dev['xseq_padded'] = [pad_sequences(thread, padding='post', maxlen=max_num_words) for thread in dev.xseq]\n",
    "#test['xseq_padded'] = [pad_sequences(thread, padding='post', maxlen=max_num_words) for thread in test.xseq]\n",
    "\n",
    "#def padding(data):\n",
    "    #padded = np.array([], dtype=object)\n",
    "    #for thread_seq in data:\n",
    "        #padded = np.concatenate(padded, pad_sequences(thread_seq, padding='post', maxlen=max_num_words), axis=0)\n",
    "        #padded.append(pad_sequences(thread_seq, padding='post', maxlen=max_num_words))\n",
    "    #return padded\n",
    "\n",
    "train_xseq_padded= padding(max_num_tweets, max_num_words, train.xseq.values).astype(int)\n",
    "dev_xseq_padded = padding(max_num_tweets, max_num_words, dev.xseq.values).astype(int)\n",
    "test_xseq_padded = padding(max_num_tweets, max_num_words, test.xseq.values).astype(int)\n",
    "train_xseq_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "model_w2v = api.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# creating an matrix with zeroes of shape vocab x embedding dimension\n",
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "# Iterate through word, index in the dictionary\n",
    "for word, i in word_index.items():\n",
    "    # extract the corresponding vector for the vocab indice of same word\n",
    "    try:\n",
    "        embedding_vector = model_w2v[word]\n",
    "        if embedding_vector is not None:\n",
    "            # Storing it in a matrix\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13116"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([line.any() for line in embedding_matrix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model and Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, TimeDistributed, Embedding, Dense, Dropout, Masking\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Size and Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1_units = 64\n",
    "lstm2_units = 32\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train), y_train)\n",
    "\n",
    "def create_model(learn_rate=0.01):\n",
    "\temb_dim = 50\n",
    "\tembedding_layer = Embedding(input_dim=vocab_size, output_dim=emb_dim,\n",
    "\t\t\t\t\t\t\t\tinput_length=max_num_words, weights=[embedding_matrix], trainable=False)\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(TimeDistributed(embedding_layer, input_shape=(max_num_tweets, max_num_words)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Masking(mask_value=0))\n",
    "\tmodel.add(TimeDistributed(LSTM(lstm1_units), input_shape=(max_num_tweets, max_num_words, emb_dim)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Masking(mask_value=0))\n",
    "\tmodel.add(LSTM(lstm2_units))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\tmodel.compile(optimizer = Adam(lr=learn_rate),\n",
    "\t\t\t\tloss='binary_crossentropy',\n",
    "\t\t\t\tmetrics = ['accuracy', keras.metrics.FalseNegatives(name=\"fn\"), keras.metrics.FalsePositives(name=\"fp\"),\n",
    "\t\t\t\t\t\t\tkeras.metrics.TrueNegatives(name=\"tn\"), keras.metrics.TruePositives(name=\"tp\")])\n",
    "\treturn model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=5, batch_size=32, verbose=0)\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.3, 0.2, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(train_xseq_padded, y_train, class_weight = class_weights)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ### Testing: lstm1_units = 16, lstm2_units = 8, lr = 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1790 samples, validate on 592 samples\n",
      "Epoch 1/5\n",
      "1790/1790 [==============================] - 49s 27ms/step - loss: 0.5903 - accuracy: 0.7453 - fn: 390.0000 - fp: 66.0000 - tn: 1324.0000 - tp: 10.0000 - val_loss: 0.5390 - val_accuracy: 0.7703 - val_fn: 136.0000 - val_fp: 0.0000e+00 - val_tn: 456.0000 - val_tp: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1312/1790 [====================>.........] - ETA: 11s - loss: 0.5434 - accuracy: 0.7790 - fn: 290.0000 - fp: 0.0000e+00 - tn: 1022.0000 - tp: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-b8392e12a6f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_xseq_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parameter tuning\n",
    "lstm1_unitsL = [16]#[64, 32, 16]\n",
    "lstm2_unitsL = [8] #[32, 16, 8]\n",
    "lrL = [0.3, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "#dropout\n",
    "\n",
    "emb_dim = 50\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train), y_train)\n",
    "\n",
    "for lstm1_units, lstm2_units in zip(lstm1_unitsL, lstm2_unitsL):\n",
    "    for lr in lrL:\n",
    "        print('--- ### Testing: lstm1_units = {}, lstm2_units = {}, lr = {}'.format(lstm1_units, lstm2_units, lr))\n",
    "\n",
    "        model = Sequential()\n",
    "        embedding_layer = Embedding(input_dim=vocab_size, output_dim=emb_dim,\n",
    "                                    input_length=max_num_words, weights=[embedding_matrix], trainable=False)\n",
    "        model.add(TimeDistributed(embedding_layer, input_shape=(max_num_tweets, max_num_words)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Masking(mask_value=0))\n",
    "        model.add(TimeDistributed(LSTM(lstm1_units, recurrent_dropout = 0.5), input_shape=(max_num_tweets, max_num_words, emb_dim)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Masking(mask_value=0))\n",
    "        model.add(LSTM(lstm2_units, recurrent_dropout = 0.5))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer = Adam(lr=lr),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics = ['accuracy', keras.metrics.FalseNegatives(name=\"fn\"), keras.metrics.FalsePositives(name=\"fp\"),\n",
    "                                keras.metrics.TrueNegatives(name=\"tn\"), keras.metrics.TruePositives(name=\"tp\")])\n",
    "\n",
    "        model.fit(\n",
    "            train_xseq_padded,\n",
    "            y_train,\n",
    "            batch_size = batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(dev_xseq_padded, y_dev),\n",
    "            class_weight=class_weights\n",
    "        )\n",
    "\n",
    "#loss, accuracy = model.evaluate(dev_xseq_padded, y_dev, verbose=False)\n",
    "#print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_76 (TimeDis (None, 305, 30, 50)       792550    \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 305, 30, 50)       0         \n",
      "_________________________________________________________________\n",
      "masking_42 (Masking)         (None, 305, 30, 50)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_77 (TimeDis (None, 305, 64)           29440     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 305, 64)           0         \n",
      "_________________________________________________________________\n",
      "masking_43 (Masking)         (None, 305, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_77 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 834,439\n",
      "Trainable params: 834,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=emb_dim,\n",
    "                                    input_length=max_num_words, weights=[embedding_matrix], trainable=False)\n",
    "model.add(TimeDistributed(embedding_layer, input_shape=(max_num_tweets, max_num_words)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Masking(mask_value=0))\n",
    "model.add(TimeDistributed(LSTM(lstm1_units, recurrent_dropout = 0.5), input_shape=(max_num_tweets, max_num_words, emb_dim)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Masking(mask_value=0))\n",
    "model.add(LSTM(lstm2_units, recurrent_dropout = 0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = Adam(lr=lr),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics = ['accuracy', keras.metrics.FalseNegatives(name=\"fn\"), keras.metrics.FalsePositives(name=\"fp\"),\n",
    "                    keras.metrics.TrueNegatives(name=\"tn\"), keras.metrics.TruePositives(name=\"tp\"),])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1790 samples, validate on 592 samples\n",
      "Epoch 1/5\n",
      "1790/1790 [==============================] - 204s 114ms/step - loss: 0.5467 - accuracy: 0.7771 - fn: 399.0000 - fp: 0.0000e+00 - tn: 1390.0000 - tp: 1.0000 - val_loss: 0.5483 - val_accuracy: 0.7703 - val_fn: 136.0000 - val_fp: 0.0000e+00 - val_tn: 456.0000 - val_tp: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1790/1790 [==============================] - 191s 107ms/step - loss: 0.5376 - accuracy: 0.7765 - fn: 400.0000 - fp: 0.0000e+00 - tn: 1390.0000 - tp: 0.0000e+00 - val_loss: 0.5412 - val_accuracy: 0.7703 - val_fn: 136.0000 - val_fp: 0.0000e+00 - val_tn: 456.0000 - val_tp: 0.0000e+00\n",
      "Epoch 3/5\n",
      " 320/1790 [====>.........................] - ETA: 2:23 - loss: 0.5164 - accuracy: 0.7906 - fn: 67.0000 - fp: 0.0000e+00 - tn: 253.0000 - tp: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-3e473436e19a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_xseq_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train), y_train)\n",
    "\n",
    "model.fit(\n",
    "    train_xseq_padded,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(dev_xseq_padded, y_dev),\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(dev_xseq_padded, y_dev, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xseq_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-e61fa8099064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m model.fit(\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mxseq_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xseq_train' is not defined"
     ]
    }
   ],
   "source": [
    "lstm1_units = 32\n",
    "lstm2_units = 16\n",
    "lr = \n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train), y_train)\n",
    "emb_dim = 50\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=50, input_length=max_num_words, weights=[embedding_matrix], trainable=False)\n",
    "\n",
    "model = Sequential(name=\"lstm\")\n",
    "model.add(TimeDistributed(embedding_layer, input_shape=(None, max_num_words)))\n",
    "model.add(TimeDistributed(LSTM(lstm1_units), input_shape=(None, max_num_words, emb_dim)))\n",
    "model.add(LSTM(lstm2_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = Adam(lr=0.000001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = metrics)\n",
    "\n",
    "counts = Counter(y_train)\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    xseq_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    verbose=True,\n",
    "    validation_data=(xseq_dev, y_dev),\n",
    "    class_weight=class_weight\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(xseq_dev, y_dev, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961692],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695],\n",
       "       [0.43961695]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_xseq_padded)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1788, 305, 30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xseq_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1788 samples, validate on 590 samples\n",
      "Epoch 1/20\n",
      "1788/1788 [==============================] - 93s 52ms/step - loss: 0.5328 - accuracy: 0.7763 - val_loss: 0.5386 - val_accuracy: 0.7712\n",
      "Epoch 2/20\n",
      "1788/1788 [==============================] - 98s 55ms/step - loss: 0.5321 - accuracy: 0.7763 - val_loss: 0.5388 - val_accuracy: 0.7712\n",
      "Epoch 3/20\n",
      "1788/1788 [==============================] - 91s 51ms/step - loss: 0.5330 - accuracy: 0.7763 - val_loss: 0.5394 - val_accuracy: 0.7712\n",
      "Epoch 4/20\n",
      " 672/1788 [==========>...................] - ETA: 51s - loss: 0.5259 - accuracy: 0.7812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0d4358e7865c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxseq_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxseq_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxseq_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing Accuracy:  {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(xseq_train, y_train, epochs=20, verbose=True, validation_data=(xseq_dev, y_dev), batch_size=32)\n",
    "\n",
    "loss, accuracy = model.evaluate(xseq_dev, y_dev, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
